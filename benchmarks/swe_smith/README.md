# SWE-smith Evaluation Pipeline

Evaluate models on [SWE-smith](https://huggingface.co/datasets/SWE-bench/SWE-smith) via the [Doubleword](https://docs.doubleword.ai/) batch API, then build per-cluster error rate profiles for Nordlys routing.

## Prerequisites

- Python 3.12+ with `uv`
- Docker Desktop with Rosetta enabled
- [Doubleword API key](https://app.doubleword.ai)
- **Clustering data** at `supernova/clustering_swe_smith/cluster_full_dataset/` — this directory must contain `cluster_assignments.json` (41,091 instances mapped to 66 clusters via HDBSCAN) and `selected_cluster_centroids.json`. Generated by the notebooks in `supernova/clustering_swe_smith/`.

## Setup

```bash
cd benchmarks
uv sync
```

Add your API key to `swe_smith/.env`:

```
DOUBLEWORD_API_KEY=your-key-here
```

## Pipeline

All commands run from `benchmarks/`. Set your model and output directory:

```bash
source swe_smith/.env

MODEL="Qwen/Qwen3-VL-30B-A3B-Instruct-FP8"
RUN_DIR="results/qwen3-30b"
RUN_ID="qwen3-30b-swe-smith-v1"
```

### 1. Sample Instances

Sample from each of the 66 semantic clusters:

```bash
uv run python -m swe_smith.scripts.sample_instances \
    --output "$RUN_DIR/sampled_ids.json" \
    --cluster-map "$RUN_DIR/cluster_map.json"
```

### 2. Pre-fetch Source Files (optional)

Fetch relevant source files from Docker containers for prompt context. Reusable across models; only run once.

```bash
uv run python -m swe_smith.scripts.prefetch_files \
    --input "$RUN_DIR/sampled_ids.json" \
    --output "$RUN_DIR/file_contents.jsonl" \
    --workers 5
```

### 3. Run Inference

The [autobatcher SDK](https://github.com/doublewordai/autobatcher) batches requests automatically. Supports resume on re-run.

```bash
uv run python -m swe_smith.scripts.run_autobatch \
    --sampled-ids "$RUN_DIR/sampled_ids.json" \
    --file-contents "$RUN_DIR/file_contents.jsonl" \
    --model "$MODEL" \
    --output "$RUN_DIR/predictions.jsonl" \
    --completion-window 1h
```

Test with `--limit 2` first to verify your API key and model work.

### 4. Evaluate Patches

```bash
uv run python -m swesmith.harness.eval \
    -p "$RUN_DIR/predictions.jsonl" \
    --run_id "$RUN_ID" \
    -w 10
```

### 5. Build Nordlys Profile

```bash
uv run python -m swe_smith.scripts.build_profile \
    --report "logs/run_evaluation/$RUN_ID/report.json" \
    --cluster-map "$RUN_DIR/cluster_map.json" \
    --model "$MODEL" \
    --output "results/profiles/$RUN_ID/profile.json"
```

To evaluate another model, set new `MODEL`/`RUN_DIR`/`RUN_ID` values and repeat steps 3-5.

## Manual Batch Workflow

For debugging, step 3 can be split into `prepare_batch` → `submit_batch` → `collect_results`. See `scripts/prepare_batch.py --help` etc.

## Troubleshooting

| Problem | Solution |
|---------|----------|
| `Model 'X' has not been configured` | Check your [Doubleword dashboard](https://app.doubleword.ai) for available models |
| `DOUBLEWORD_API_KEY not set` | `source swe_smith/.env` or `export DOUBLEWORD_API_KEY=...` |
| Container pull/startup fails | Ensure Docker Desktop + Rosetta are running |
| Batch failed | `collect_results --errors errors.jsonl` to inspect |
